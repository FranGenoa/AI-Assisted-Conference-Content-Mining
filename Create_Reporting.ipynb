{"cells":[{"cell_type":"code","source":["\"\"\"\n","Ignite 2025 - Fabric Delta Tables Builder (PySpark)\n","\n","This script loads JSON data from the Lakehouse Files, flattens nested structures,\n","joins session metadata with VTT analysis, and creates Delta tables in the Lakehouse.\n","\n","Workflow:\n","1. Load sessions_metadata.json from metadata folder\n","2. Load sessions_analysis_full.json from analysis folder\n","3. Flatten nested structures (speakers, tags, topics)\n","4. Left join metadata with analysis\n","5. Create dimension and fact tables\n","6. Save as Delta tables in Lakehouse Tables section\n","\"\"\"\n","\n","from pyspark.sql import SparkSession, DataFrame\n","from pyspark.sql import functions as F\n","from pyspark.sql.types import *\n","from datetime import datetime\n","\n","# Configuration\n","# In Fabric, use relative paths starting with 'Files/'\n","BASE_PATH = \"Files/Ignite2025_All\"\n","METADATA_FILE = f\"{BASE_PATH}/metadata/sessions_metadata.json\"\n","ANALYSIS_FILE = f\"{BASE_PATH}/analysis/sessions_analysis_full.json\"\n","\n","# Get Spark session\n","spark = SparkSession.builder.getOrCreate()\n","\n","print(\"=\" * 80)\n","print(\"Ignite 2025 - Fabric Delta Tables Builder (PySpark)\")\n","print(\"=\" * 80)\n","\n","\n","# ==============================================================================\n","# STEP 1: LOAD AND FLATTEN SESSIONS METADATA\n","# ==============================================================================\n","print(\"\\nüìÇ STEP 1: Loading sessions metadata...\")\n","\n","# Load JSON with nested structures\n","df_sessions_raw = spark.read.option(\"multiLine\", \"true\").json(METADATA_FILE)\n","\n","print(f\"‚úÖ Loaded {df_sessions_raw.count()} sessions from metadata\")\n","print(f\"   Columns: {', '.join(df_sessions_raw.columns)}\")\n","\n","# Flatten sessions metadata\n","df_sessions = df_sessions_raw.select(\n","    \"session_id\",\n","    \"session_code\",\n","    \"title\",\n","    \"description\",\n","    \"level\",\n","    \"session_type\",\n","    \"duration_minutes\",\n","    \"start_time\",\n","    \"end_time\",\n","    \"speaker_names\",\n","    \"location\",\n","    \"venue\",\n","    \"room\",\n","    \"slide_deck_url\",\n","    \"has_slides\",\n","    \"video_url\",\n","    \"has_video\",\n","    \"captions_url\",\n","    \"extracted_at\",\n","    # Keep nested arrays for dimension tables\n","    F.col(\"speakers\").alias(\"speakers_array\"),\n","    F.col(\"tags\").alias(\"tags_array\"),\n","    F.col(\"topics\").alias(\"topics_array\"),\n",")\n","\n","# Parse timestamps\n","df_sessions = df_sessions \\\n","    .withColumn(\"start_time\", F.to_timestamp(\"start_time\")) \\\n","    .withColumn(\"end_time\", F.to_timestamp(\"end_time\")) \\\n","    .withColumn(\"extracted_at\", F.to_timestamp(\"extracted_at\"))\n","\n","print(f\"‚úÖ Flattened sessions metadata: {df_sessions.count()} rows\")\n","\n","\n","# ==============================================================================\n","# STEP 2: LOAD AND FLATTEN ANALYSIS DATA\n","# ==============================================================================\n","print(\"\\nüìÇ STEP 2: Loading analysis data...\")\n","\n","# Load analysis JSON\n","df_analysis_raw = spark.read.option(\"multiLine\", \"true\").json(ANALYSIS_FILE)\n","\n","print(f\"‚úÖ Loaded {df_analysis_raw.count()} analyzed sessions\")\n","\n","# Flatten analysis data\n","df_analysis = df_analysis_raw.select(\n","    \"session_code\",\n","    F.col(\"session_title\").alias(\"analyzed_title\"),\n","    \"summary\",\n","    \"target_audience\",\n","    \"technical_level\",\n","    \"analyzed_at\",\n","    # Flatten arrays to pipe-separated strings for fact table\n","    F.when(F.col(\"key_topics\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"key_topics\")))\n","     .otherwise(F.lit(None)).alias(\"key_topics\"),\n","    F.when(F.col(\"microsoft_features_mentioned\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"microsoft_features_mentioned\")))\n","     .otherwise(F.lit(None)).alias(\"microsoft_features_mentioned\"),\n","    F.when(F.col(\"new_announcements\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"new_announcements\")))\n","     .otherwise(F.lit(None)).alias(\"new_announcements\"),\n","    F.when(F.col(\"demos_described\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"demos_described\")))\n","     .otherwise(F.lit(None)).alias(\"demos_described\"),\n","    F.when(F.col(\"best_practices\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"best_practices\")))\n","     .otherwise(F.lit(None)).alias(\"best_practices\"),\n","    F.when(F.col(\"key_quotes\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"key_quotes\")))\n","     .otherwise(F.lit(None)).alias(\"key_quotes\"),\n","    F.when(F.col(\"action_items\").isNotNull(), \n","           F.concat_ws(\"|\", F.col(\"action_items\")))\n","     .otherwise(F.lit(None)).alias(\"action_items\"),\n",")\n","\n","# Add flag for successful analysis (based on summary being populated)\n","df_analysis = df_analysis.withColumn(\n","    \"has_analysis\",\n","    F.when(F.col(\"summary\").isNotNull() & (F.col(\"summary\") != \"\"), True)\n","     .otherwise(False)\n",")\n","\n","# Parse analyzed_at timestamp\n","df_analysis = df_analysis.withColumn(\n","    \"analyzed_at\", \n","    F.to_timestamp(\"analyzed_at\")\n",")\n","\n","print(f\"‚úÖ Flattened analysis data: {df_analysis.count()} rows\")\n","\n","\n","# ==============================================================================\n","# STEP 3: LEFT JOIN TO CREATE UNIFIED TABLE\n","# ==============================================================================\n","print(\"\\nüîó STEP 3: Creating unified table (left join)...\")\n","\n","df_unified = df_sessions.join(\n","    df_analysis,\n","    on=\"session_code\",\n","    how=\"left\"\n",")\n","\n","# Fill has_analysis with False for sessions without analysis\n","df_unified = df_unified.fillna({\"has_analysis\": False})\n","\n","sessions_with_analysis = df_unified.filter(F.col(\"has_analysis\") == True).count()\n","sessions_without_analysis = df_unified.filter(F.col(\"has_analysis\") == False).count()\n","\n","print(f\"‚úÖ Unified table created: {df_unified.count()} rows\")\n","print(f\"   Sessions with analysis: {sessions_with_analysis}\")\n","print(f\"   Sessions without analysis: {sessions_without_analysis}\")\n","\n","\n","# ==============================================================================\n","# STEP 4: CREATE DIMENSION TABLES\n","# ==============================================================================\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Date\n","# ------------------------------------------------------------------------------\n","print(\"\\nüìÖ Creating Dim_Date...\")\n","\n","df_dates = df_unified.select(\n","    F.col(\"start_time\").alias(\"datetime\")\n",").union(\n","    df_unified.select(F.col(\"end_time\").alias(\"datetime\"))\n",").filter(F.col(\"datetime\").isNotNull())\n","\n","dim_date = df_dates.select(\n","    F.date_format(\"datetime\", \"yyyyMMdd\").alias(\"date_key\"),\n","    F.to_date(\"datetime\").alias(\"date\"),\n","    F.year(\"datetime\").alias(\"year\"),\n","    F.month(\"datetime\").alias(\"month\"),\n","    F.date_format(\"datetime\", \"MMMM\").alias(\"month_name\"),\n","    F.dayofmonth(\"datetime\").alias(\"day\"),\n","    F.date_format(\"datetime\", \"EEEE\").alias(\"day_of_week\"),\n","    F.quarter(\"datetime\").alias(\"quarter\")\n",").distinct().orderBy(\"date_key\")\n","\n","print(f\"‚úÖ Dim_Date created: {dim_date.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Session (with surrogate key)\n","# ------------------------------------------------------------------------------\n","print(\"\\nüìä Creating Dim_Session...\")\n","\n","dim_session = df_unified.select(\n","    \"session_id\",\n","    \"session_code\",\n","    \"title\",\n","    \"description\",\n","    \"duration_minutes\",\n","    \"start_time\",\n","    \"end_time\",\n","    \"has_slides\",\n","    \"has_video\",\n","    \"has_analysis\",\n","    \"slide_deck_url\",\n","    \"video_url\"\n",").distinct() \\\n"," .withColumn(\"session_key\", F.monotonically_increasing_id() + 1) \\\n"," .withColumn(\"start_date_key\", F.date_format(\"start_time\", \"yyyyMMdd\")) \\\n"," .withColumn(\"end_date_key\", F.date_format(\"end_time\", \"yyyyMMdd\"))\n","\n","# Reorder columns to put session_key first\n","dim_session = dim_session.select(\n","    \"session_key\",\n","    \"session_id\",\n","    \"session_code\",\n","    \"title\",\n","    \"description\",\n","    \"duration_minutes\",\n","    \"start_time\",\n","    \"end_time\",\n","    \"start_date_key\",\n","    \"end_date_key\",\n","    \"has_slides\",\n","    \"has_video\",\n","    \"has_analysis\",\n","    \"slide_deck_url\",\n","    \"video_url\"\n",")\n","\n","print(f\"‚úÖ Dim_Session created: {dim_session.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_SessionType\n","# ------------------------------------------------------------------------------\n","print(\"\\nüß© Creating Dim_SessionType...\")\n","\n","dim_session_type = df_unified.select(\"session_type\") \\\n","    .distinct() \\\n","    .filter(F.col(\"session_type\").isNotNull()) \\\n","    .orderBy(\"session_type\") \\\n","    .withColumn(\"session_type_key\", F.monotonically_increasing_id() + 1)\n","\n","print(f\"‚úÖ Dim_SessionType created: {dim_session_type.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_SessionLevel\n","# ------------------------------------------------------------------------------\n","print(\"\\nüß© Creating Dim_SessionLevel...\")\n","\n","dim_session_level = df_unified.select(\n","    F.col(\"level\").alias(\"session_level\")\n",").distinct() \\\n"," .filter(F.col(\"session_level\").isNotNull()) \\\n"," .orderBy(\"session_level\") \\\n"," .withColumn(\"session_level_key\", F.monotonically_increasing_id() + 1)\n","\n","print(f\"‚úÖ Dim_SessionLevel created: {dim_session_level.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Location\n","# ------------------------------------------------------------------------------\n","print(\"\\nüß© Creating Dim_Location...\")\n","\n","dim_location = df_unified.select(\"venue\", \"room\", \"location\") \\\n","    .distinct() \\\n","    .filter(\n","        (F.col(\"venue\").isNotNull() & (F.col(\"venue\") != \"\")) |\n","        (F.col(\"room\").isNotNull() & (F.col(\"room\") != \"\")) |\n","        (F.col(\"location\").isNotNull() & (F.col(\"location\") != \"\"))\n","    ) \\\n","    .orderBy(\"venue\", \"room\") \\\n","    .withColumn(\"location_key\", F.monotonically_increasing_id() + 1)\n","\n","print(f\"‚úÖ Dim_Location created: {dim_location.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Speaker (unique speakers only)\n","# ------------------------------------------------------------------------------\n","print(\"\\nüë§ Creating Dim_Speaker...\")\n","\n","# Explode speakers array and get unique speakers\n","dim_speaker = df_unified.select(\n","    F.explode_outer(\"speakers_array\").alias(\"speaker\")\n",").select(\n","    F.col(\"speaker.fullName\").alias(\"speaker_name\"),\n","    F.col(\"speaker.title\").alias(\"speaker_title\"),\n","    F.col(\"speaker.company\").alias(\"speaker_company\")\n",").filter(F.col(\"speaker_name\").isNotNull()) \\\n"," .distinct() \\\n"," .orderBy(\"speaker_name\") \\\n"," .withColumn(\"speaker_key\", F.monotonically_increasing_id() + 1)\n","\n","# Reorder columns\n","dim_speaker = dim_speaker.select(\n","    \"speaker_key\",\n","    \"speaker_name\",\n","    \"speaker_title\",\n","    \"speaker_company\"\n",")\n","\n","print(f\"‚úÖ Dim_Speaker created: {dim_speaker.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Tag (unique tags only)\n","# ------------------------------------------------------------------------------\n","print(\"\\nüè∑Ô∏è Creating Dim_Tag...\")\n","\n","# Explode tags array and get unique tags\n","dim_tag = df_unified.select(\n","    F.explode_outer(\"tags_array\").alias(\"tag_name\")\n",").filter(F.col(\"tag_name\").isNotNull()) \\\n"," .distinct() \\\n"," .orderBy(\"tag_name\") \\\n"," .withColumn(\"tag_key\", F.monotonically_increasing_id() + 1)\n","\n","print(f\"‚úÖ Dim_Tag created: {dim_tag.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Dim_Topic (unique topics only)\n","# ------------------------------------------------------------------------------\n","print(\"\\nüè∑Ô∏è Creating Dim_Topic...\")\n","\n","# Explode topics array and get unique topics\n","dim_topic = df_unified.select(\n","    F.explode_outer(\"topics_array\").alias(\"topic\")\n",").select(\n","    F.when(F.col(\"topic.displayValue\").isNotNull(), F.col(\"topic.displayValue\"))\n","     .otherwise(F.col(\"topic.logicalValue\")).alias(\"topic_name\")\n",").filter(F.col(\"topic_name\").isNotNull()) \\\n"," .distinct() \\\n"," .orderBy(\"topic_name\") \\\n"," .withColumn(\"topic_key\", F.monotonically_increasing_id() + 1)\n","\n","print(f\"‚úÖ Dim_Topic created: {dim_topic.count()} rows\")\n","\n","\n","# ==============================================================================\n","# STEP 5: CREATE BRIDGE TABLES (Many-to-Many)\n","# ==============================================================================\n","\n","# ------------------------------------------------------------------------------\n","# Bridge_SessionSpeaker\n","# ------------------------------------------------------------------------------\n","print(\"\\nüîó Creating Bridge_SessionSpeaker...\")\n","\n","bridge_session_speaker = df_unified.select(\n","    \"session_code\",\n","    F.explode_outer(\"speakers_array\").alias(\"speaker\")\n",").select(\n","    \"session_code\",\n","    F.col(\"speaker.fullName\").alias(\"speaker_name\")\n",").filter(F.col(\"speaker_name\").isNotNull()) \\\n"," .join(dim_session.select(\"session_key\", \"session_code\"), on=\"session_code\", how=\"inner\") \\\n"," .join(dim_speaker.select(\"speaker_key\", \"speaker_name\"), on=\"speaker_name\", how=\"inner\") \\\n"," .select(\"session_key\", \"speaker_key\") \\\n"," .distinct()\n","\n","print(f\"‚úÖ Bridge_SessionSpeaker created: {bridge_session_speaker.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Bridge_SessionTag\n","# ------------------------------------------------------------------------------\n","print(\"\\nüîó Creating Bridge_SessionTag...\")\n","\n","bridge_session_tag = df_unified.select(\n","    \"session_code\",\n","    F.explode_outer(\"tags_array\").alias(\"tag_name\")\n",").filter(F.col(\"tag_name\").isNotNull()) \\\n"," .join(dim_session.select(\"session_key\", \"session_code\"), on=\"session_code\", how=\"inner\") \\\n"," .join(dim_tag, on=\"tag_name\", how=\"inner\") \\\n"," .select(\"session_key\", \"tag_key\") \\\n"," .distinct()\n","\n","print(f\"‚úÖ Bridge_SessionTag created: {bridge_session_tag.count()} rows\")\n","\n","# ------------------------------------------------------------------------------\n","# Bridge_SessionTopic\n","# ------------------------------------------------------------------------------\n","print(\"\\nüîó Creating Bridge_SessionTopic...\")\n","\n","bridge_session_topic = df_unified.select(\n","    \"session_code\",\n","    F.explode_outer(\"topics_array\").alias(\"topic\")\n",").select(\n","    \"session_code\",\n","    F.when(F.col(\"topic.displayValue\").isNotNull(), F.col(\"topic.displayValue\"))\n","     .otherwise(F.col(\"topic.logicalValue\")).alias(\"topic_name\")\n",").filter(F.col(\"topic_name\").isNotNull()) \\\n"," .join(dim_session.select(\"session_key\", \"session_code\"), on=\"session_code\", how=\"inner\") \\\n"," .join(dim_topic, on=\"topic_name\", how=\"inner\") \\\n"," .select(\"session_key\", \"topic_key\") \\\n"," .distinct()\n","\n","print(f\"‚úÖ Bridge_SessionTopic created: {bridge_session_topic.count()} rows\")\n","\n","\n","# ==============================================================================\n","# STEP 6: CREATE FACT TABLE WITH SURROGATE KEYS\n","# ==============================================================================\n","print(\"\\nüìà Creating Fact_SessionAnalysis...\")\n","\n","# Prepare fact table with surrogate keys\n","fact_base = df_unified.select(\n","    \"session_code\",\n","    \"session_type\",\n","    F.col(\"level\").alias(\"session_level\"),\n","    \"venue\",\n","    \"room\",\n","    \"location\",\n","    \"start_time\",\n","    \"has_analysis\",\n","    \"summary\",\n","    \"key_topics\",\n","    \"microsoft_features_mentioned\",\n","    \"new_announcements\",\n","    \"demos_described\",\n","    \"best_practices\",\n","    \"target_audience\",\n","    \"technical_level\",\n","    \"key_quotes\",\n","    \"action_items\",\n","    \"analyzed_at\"\n",").distinct()\n","\n","# Join to get session_key\n","fact_base = fact_base.join(\n","    dim_session.select(\"session_key\", \"session_code\"),\n","    on=\"session_code\",\n","    how=\"left\"\n",")\n","\n","# Add start_date_key\n","fact_base = fact_base.withColumn(\n","    \"start_date_key\",\n","    F.date_format(\"start_time\", \"yyyyMMdd\")\n",")\n","\n","# Join to get session_type_key\n","fact_base = fact_base.join(\n","    dim_session_type,\n","    on=\"session_type\",\n","    how=\"left\"\n",")\n","\n","# Join to get session_level_key\n","fact_base = fact_base.join(\n","    dim_session_level,\n","    on=\"session_level\",\n","    how=\"left\"\n",")\n","\n","# Join to get location_key\n","fact_base = fact_base.join(\n","    dim_location,\n","    on=[\"venue\", \"room\", \"location\"],\n","    how=\"left\"\n",")\n","\n","# Select final fact columns\n","fact_analysis = fact_base.select(\n","    \"session_key\",\n","    \"start_date_key\",\n","    \"session_type_key\",\n","    \"session_level_key\",\n","    \"location_key\",\n","    \"has_analysis\",\n","    \"summary\",\n","    \"key_topics\",\n","    \"microsoft_features_mentioned\",\n","    \"new_announcements\",\n","    \"demos_described\",\n","    \"best_practices\",\n","    \"target_audience\",\n","    \"technical_level\",\n","    \"key_quotes\",\n","    \"action_items\",\n","    \"analyzed_at\"\n",")\n","\n","# Add metric columns (counts)\n","fact_analysis = fact_analysis \\\n","    .withColumn(\"key_topics_count\", \n","                F.when(F.col(\"key_topics\").isNotNull(), \n","                       F.size(F.split(F.col(\"key_topics\"), \"\\\\|\")))\n","                 .otherwise(0)) \\\n","    .withColumn(\"features_count\",\n","                F.when(F.col(\"microsoft_features_mentioned\").isNotNull(),\n","                       F.size(F.split(F.col(\"microsoft_features_mentioned\"), \"\\\\|\")))\n","                 .otherwise(0)) \\\n","    .withColumn(\"announcements_count\",\n","                F.when(F.col(\"new_announcements\").isNotNull(),\n","                       F.size(F.split(F.col(\"new_announcements\"), \"\\\\|\")))\n","                 .otherwise(0)) \\\n","    .withColumn(\"best_practices_count\",\n","                F.when(F.col(\"best_practices\").isNotNull(),\n","                       F.size(F.split(F.col(\"best_practices\"), \"\\\\|\")))\n","                 .otherwise(0)) \\\n","    .withColumn(\"action_items_count\",\n","                F.when(F.col(\"action_items\").isNotNull(),\n","                       F.size(F.split(F.col(\"action_items\"), \"\\\\|\")))\n","                 .otherwise(0))\n","\n","print(f\"‚úÖ Fact_SessionAnalysis created: {fact_analysis.count()} rows\")\n","\n","\n","# ==============================================================================\n","# STEP 7: SAVE AS DELTA TABLES IN LAKEHOUSE\n","# ==============================================================================\n","print(\"\\nüíæ Saving tables to Lakehouse (Delta format)...\")\n","\n","tables = {\n","    \"Dim_Date\": dim_date,\n","    \"Dim_Session\": dim_session,\n","    \"Dim_SessionType\": dim_session_type,\n","    \"Dim_SessionLevel\": dim_session_level,\n","    \"Dim_Location\": dim_location,\n","    \"Dim_Speaker\": dim_speaker,\n","    \"Dim_Tag\": dim_tag,\n","    \"Dim_Topic\": dim_topic,\n","    \"Bridge_SessionSpeaker\": bridge_session_speaker,\n","    \"Bridge_SessionTag\": bridge_session_tag,\n","    \"Bridge_SessionTopic\": bridge_session_topic,\n","    \"Fact_SessionAnalysis\": fact_analysis,\n","}\n","\n","for table_name, df in tables.items():\n","    print(f\"\\n   üíæ Saving {table_name}...\")\n","    \n","    # Write as Delta table (overwrites if exists)\n","    df.write \\\n","        .format(\"delta\") \\\n","        .mode(\"overwrite\") \\\n","        .option(\"overwriteSchema\", \"true\") \\\n","        .saveAsTable(table_name)\n","    \n","    print(f\"   ‚úÖ {table_name} saved: {df.count()} rows\")\n","\n","# Also save the unified table for reference\n","print(f\"\\n   üíæ Saving Unified_Sessions...\")\n","df_unified.write \\\n","    .format(\"delta\") \\\n","    .mode(\"overwrite\") \\\n","    .option(\"overwriteSchema\", \"true\") \\\n","    .saveAsTable(\"Unified_Sessions\")\n","\n","print(f\"   ‚úÖ Unified_Sessions saved: {df_unified.count()} rows\")\n","\n","\n","# ==============================================================================\n","# SUMMARY\n","# ==============================================================================\n","print(\"\\n\" + \"=\" * 80)\n","print(\"‚úÖ DELTA TABLES CREATION COMPLETE\")\n","print(\"=\" * 80)\n","\n","print(\"\\nüìä Tables created in Lakehouse:\")\n","print(f\"  ‚Ä¢ Unified_Sessions: {df_unified.count():,} rows √ó {len(df_unified.columns)} columns\")\n","print(f\"  ‚Ä¢ Dim_Date: {dim_date.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_Session: {dim_session.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_SessionType: {dim_session_type.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_SessionLevel: {dim_session_level.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_Location: {dim_location.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_Speaker: {dim_speaker.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_Tag: {dim_tag.count():,} rows\")\n","print(f\"  ‚Ä¢ Dim_Topic: {dim_topic.count():,} rows\")\n","print(f\"  ‚Ä¢ Bridge_SessionSpeaker: {bridge_session_speaker.count():,} rows\")\n","print(f\"  ‚Ä¢ Bridge_SessionTag: {bridge_session_tag.count():,} rows\")\n","print(f\"  ‚Ä¢ Bridge_SessionTopic: {bridge_session_topic.count():,} rows\")\n","print(f\"  ‚Ä¢ Fact_SessionAnalysis: {fact_analysis.count():,} rows\")\n","\n","print(\"\\nüìä Analysis Coverage:\")\n","print(f\"  ‚Ä¢ Sessions with analysis: {sessions_with_analysis:,} ({sessions_with_analysis/df_unified.count()*100:.1f}%)\")\n","print(f\"  ‚Ä¢ Sessions without analysis: {sessions_without_analysis:,}\")\n","\n","print(\"\\nüîó Power BI Relationships (Star Schema):\")\n","print(\"  ‚ñ™ Direct to Fact (1:*):\")\n","print(\"    ‚Ä¢ Dim_Session[session_key] ‚Üí Fact_SessionAnalysis[session_key]\")\n","print(\"    ‚Ä¢ Dim_Date[date_key] ‚Üí Fact_SessionAnalysis[start_date_key]\")\n","print(\"    ‚Ä¢ Dim_SessionType[session_type_key] ‚Üí Fact_SessionAnalysis[session_type_key]\")\n","print(\"    ‚Ä¢ Dim_SessionLevel[session_level_key] ‚Üí Fact_SessionAnalysis[session_level_key]\")\n","print(\"    ‚Ä¢ Dim_Location[location_key] ‚Üí Fact_SessionAnalysis[location_key]\")\n","print(\"  ‚ñ™ Many-to-Many via Bridges (1:*):\")\n","print(\"    ‚Ä¢ Dim_Speaker[speaker_key] ‚Üí Bridge_SessionSpeaker[speaker_key]\")\n","print(\"    ‚Ä¢ Dim_Tag[tag_key] ‚Üí Bridge_SessionTag[tag_key]\")\n","print(\"    ‚Ä¢ Dim_Topic[topic_key] ‚Üí Bridge_SessionTopic[topic_key]\")\n","print(\"    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionSpeaker[session_key]\")\n","print(\"    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionTag[session_key]\")\n","print(\"    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionTopic[session_key]\")\n","\n","print(\"\\n‚ú® Done! All tables are now available in the Lakehouse Tables section.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"cb5b91d7-3ef1-43d8-ad19-a39fed23476a","normalized_state":"finished","queued_time":"2025-12-14T12:49:37.046695Z","session_start_time":null,"execution_start_time":"2025-12-14T12:49:37.0486291Z","execution_finish_time":"2025-12-14T12:51:27.6078448Z","parent_msg_id":"1280c90c-3be7-49a9-95b6-44c63d5708cc"},"text/plain":"StatementMeta(, cb5b91d7-3ef1-43d8-ad19-a39fed23476a, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["================================================================================\nIgnite 2025 - Fabric Delta Tables Builder (PySpark)\n================================================================================\n\nüìÇ STEP 1: Loading sessions metadata...\n‚úÖ Loaded 1090 sessions from metadata\n   Columns: captions_url, description, duration_minutes, end_time, extracted_at, has_slides, has_video, learning_path, level, location, room, session_code, session_id, session_type, slide_deck_url, speaker_names, speakers, start_time, tags, title, topics, venue, video_url\n‚úÖ Flattened sessions metadata: 1090 rows\n\nüìÇ STEP 2: Loading analysis data...\n‚úÖ Loaded 498 analyzed sessions\n‚úÖ Flattened analysis data: 498 rows\n\nüîó STEP 3: Creating unified table (left join)...\n‚úÖ Unified table created: 1090 rows\n   Sessions with analysis: 498\n   Sessions without analysis: 592\n\nüìÖ Creating Dim_Date...\n‚úÖ Dim_Date created: 5 rows\n\nüìä Creating Dim_Session...\n‚úÖ Dim_Session created: 1090 rows\n\nüß© Creating Dim_SessionType...\n‚úÖ Dim_SessionType created: 8 rows\n\nüß© Creating Dim_SessionLevel...\n‚úÖ Dim_SessionLevel created: 5 rows\n\nüß© Creating Dim_Location...\n‚úÖ Dim_Location created: 50 rows\n\nüë§ Creating Dim_Speaker...\n‚úÖ Dim_Speaker created: 1430 rows\n\nüè∑Ô∏è Creating Dim_Tag...\n‚úÖ Dim_Tag created: 190 rows\n\nüè∑Ô∏è Creating Dim_Topic...\n‚úÖ Dim_Topic created: 57 rows\n\nüîó Creating Bridge_SessionSpeaker...\n‚úÖ Bridge_SessionSpeaker created: 2047 rows\n\nüîó Creating Bridge_SessionTag...\n‚úÖ Bridge_SessionTag created: 1852 rows\n\nüîó Creating Bridge_SessionTopic...\n‚úÖ Bridge_SessionTopic created: 1461 rows\n\nüìà Creating Fact_SessionAnalysis...\n‚úÖ Fact_SessionAnalysis created: 1090 rows\n\nüíæ Saving tables to Lakehouse (Delta format)...\n\n   üíæ Saving Dim_Date...\n   ‚úÖ Dim_Date saved: 5 rows\n\n   üíæ Saving Dim_Session...\n   ‚úÖ Dim_Session saved: 1090 rows\n\n   üíæ Saving Dim_SessionType...\n   ‚úÖ Dim_SessionType saved: 8 rows\n\n   üíæ Saving Dim_SessionLevel...\n   ‚úÖ Dim_SessionLevel saved: 5 rows\n\n   üíæ Saving Dim_Location...\n   ‚úÖ Dim_Location saved: 50 rows\n\n   üíæ Saving Dim_Speaker...\n   ‚úÖ Dim_Speaker saved: 1430 rows\n\n   üíæ Saving Dim_Tag...\n   ‚úÖ Dim_Tag saved: 190 rows\n\n   üíæ Saving Dim_Topic...\n   ‚úÖ Dim_Topic saved: 57 rows\n\n   üíæ Saving Bridge_SessionSpeaker...\n   ‚úÖ Bridge_SessionSpeaker saved: 2047 rows\n\n   üíæ Saving Bridge_SessionTag...\n   ‚úÖ Bridge_SessionTag saved: 1852 rows\n\n   üíæ Saving Bridge_SessionTopic...\n   ‚úÖ Bridge_SessionTopic saved: 1461 rows\n\n   üíæ Saving Fact_SessionAnalysis...\n   ‚úÖ Fact_SessionAnalysis saved: 1090 rows\n\n   üíæ Saving Unified_Sessions...\n   ‚úÖ Unified_Sessions saved: 1090 rows\n\n================================================================================\n‚úÖ DELTA TABLES CREATION COMPLETE\n================================================================================\n\nüìä Tables created in Lakehouse:\n  ‚Ä¢ Unified_Sessions: 1,090 rows √ó 35 columns\n  ‚Ä¢ Dim_Date: 5 rows\n  ‚Ä¢ Dim_Session: 1,090 rows\n  ‚Ä¢ Dim_SessionType: 8 rows\n  ‚Ä¢ Dim_SessionLevel: 5 rows\n  ‚Ä¢ Dim_Location: 50 rows\n  ‚Ä¢ Dim_Speaker: 1,430 rows\n  ‚Ä¢ Dim_Tag: 190 rows\n  ‚Ä¢ Dim_Topic: 57 rows\n  ‚Ä¢ Bridge_SessionSpeaker: 2,047 rows\n  ‚Ä¢ Bridge_SessionTag: 1,852 rows\n  ‚Ä¢ Bridge_SessionTopic: 1,461 rows\n  ‚Ä¢ Fact_SessionAnalysis: 1,090 rows\n\nüìä Analysis Coverage:\n  ‚Ä¢ Sessions with analysis: 498 (45.7%)\n  ‚Ä¢ Sessions without analysis: 592\n\nüîó Power BI Relationships (Star Schema):\n  ‚ñ™ Direct to Fact (1:*):\n    ‚Ä¢ Dim_Session[session_key] ‚Üí Fact_SessionAnalysis[session_key]\n    ‚Ä¢ Dim_Date[date_key] ‚Üí Fact_SessionAnalysis[start_date_key]\n    ‚Ä¢ Dim_SessionType[session_type_key] ‚Üí Fact_SessionAnalysis[session_type_key]\n    ‚Ä¢ Dim_SessionLevel[session_level_key] ‚Üí Fact_SessionAnalysis[session_level_key]\n    ‚Ä¢ Dim_Location[location_key] ‚Üí Fact_SessionAnalysis[location_key]\n  ‚ñ™ Many-to-Many via Bridges (1:*):\n    ‚Ä¢ Dim_Speaker[speaker_key] ‚Üí Bridge_SessionSpeaker[speaker_key]\n    ‚Ä¢ Dim_Tag[tag_key] ‚Üí Bridge_SessionTag[tag_key]\n    ‚Ä¢ Dim_Topic[topic_key] ‚Üí Bridge_SessionTopic[topic_key]\n    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionSpeaker[session_key]\n    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionTag[session_key]\n    ‚Ä¢ Dim_Session[session_key] ‚Üí Bridge_SessionTopic[session_key]\n\n‚ú® Done! All tables are now available in the Lakehouse Tables section.\n"]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0675c50-cb72-41e6-b134-5b0a13c8ce1c"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"0f99be1b-e2d7-4eb0-8c68-0091f9022eeb","known_lakehouses":[{"id":"0f99be1b-e2d7-4eb0-8c68-0091f9022eeb"}],"default_lakehouse_name":"NewLakehouse","default_lakehouse_workspace_id":"af9b4eda-f3be-49b1-bac1-bf685cff4e27"}}},"nbformat":4,"nbformat_minor":5}